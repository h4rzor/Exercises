{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0adacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.nn import ModuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d411731",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text.txt\",\"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9cbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d50c7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {index: char for index, char in enumerate(vocab_size)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "507b28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ad6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {index: char for char, index in enumerate(vocab_size)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa53244e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0d5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda x: [stoi[s] for s in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd43c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = lambda x: [itos[s] for s in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b795ca4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 47, 47, 1, 58, 46, 43, 56, 43]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = encode(\"hii there\")\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3524f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'i', 'i', ' ', 't', 'h', 'e', 'r', 'e']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = decode(encoded)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aeda9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fc51973",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:int(0.9 * len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab318a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = data[int(0.9 * len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec1f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(data) == len(train_data) + len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "242b6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a2d385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ec6c142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(58)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_data[block_size]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "199c23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b26045d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fef7df63c90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eec9aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have x as an input and we have the target number as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "116b8898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp is: tensor([18]); out is: 56\n",
      "inp is: tensor([18, 47]); out is: 57\n",
      "inp is: tensor([18, 47, 56]); out is: 58\n",
      "inp is: tensor([18, 47, 56, 57]); out is: 1\n",
      "inp is: tensor([18, 47, 56, 57, 58]); out is: 15\n",
      "inp is: tensor([18, 47, 56, 57, 58,  1]); out is: 47\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(x) - 1):\n",
    "    inp = x[:i]\n",
    "    out = x[i+1]\n",
    "    print(f\"inp is: {inp}; out is: {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fde019b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    index = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([train_data[i:i+block_size] for i in index])\n",
    "    y = torch.stack([train_data[i+1:i+block_size+1] for i in index])\n",
    "    return x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5c2b1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 74928, 231851, 934226, 560077])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.randint(len(train_data) - block_size, (batch_size, ))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08d15e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.stack([train_data[i:i+block_size] for i in index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8c491ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.stack([train_data[i+1:i+block_size+1] for i in index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b58c6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[56,  6,  0, 24, 43, 58,  1, 61],\n",
       "        [39, 47, 51,  1, 58, 46, 39, 58],\n",
       "        [52, 45,  1, 58, 53,  1, 57, 39],\n",
       "        [43, 47, 52, 45,  1, 46, 53, 50]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36eb89b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  0, 24, 43, 58,  1, 61, 46],\n",
       "        [47, 51,  1, 58, 46, 39, 58,  1],\n",
       "        [45,  1, 58, 53,  1, 57, 39, 63],\n",
       "        [47, 52, 45,  1, 46, 53, 50, 47]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cc6dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e4b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86e8d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, index, targets=None):\n",
    "        output = self.embedding_layer(index)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(output.view(batch_size * block_size, -1), yb.view(-1))\n",
    "        \n",
    "        return output, loss\n",
    "    \n",
    "    def generate(self, index, max_new_token):\n",
    "        for i in range(max_new_token):\n",
    "            output, loss = self(index)\n",
    "            output = output[:, -1, :].softmax(-1)\n",
    "            index_next = torch.multinomial(output, num_samples=1)\n",
    "            index = torch.cat((index, index_next), dim=1)\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ac447d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(len(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99dbd01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, loss = model(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01e83668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 65])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "719fe152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.174387269895637"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-math.log(1/len(vocab_size)) #So the model is very convoluted at the moment\n",
    "#The lowest error should be 4.1, but it's higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0b647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f885a79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78a90738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n&rEnLTjLDJIcLVR'JIHDTHdhsV\\nv\\nwxh,nhUYZzAEOZHpgo3q3ZYZes$zuGw,;eMk QqACRfCLgxiW3.O!zDLgA YsTb!dHb!;pK\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decode(model.generate(index = torch.zeros((1, 1), dtype=torch.long), max_new_token=100)[0].tolist())\n",
    "output = \"\".join(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07f4caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f01b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "645d0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, optimizer):\n",
    "    for i in range(epochs):\n",
    "        x, y = get_batch(\"train\")\n",
    "        output, loss = model(x, y)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"{i}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11388705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, loss: 4.3336710929870605\n",
      "1000, loss: 4.190601825714111\n",
      "2000, loss: 3.6422181129455566\n",
      "3000, loss: 3.4271457195281982\n",
      "4000, loss: 3.514732837677002\n",
      "5000, loss: 3.316194534301758\n",
      "6000, loss: 3.0088391304016113\n",
      "7000, loss: 3.1258537769317627\n",
      "8000, loss: 3.1442017555236816\n",
      "9000, loss: 3.0557634830474854\n"
     ]
    }
   ],
   "source": [
    "train(epochs, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d2209ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nrmr hotk\\neIL;,\\n\\ntfTBBZYLst: rtGhBx&Lmkko\\nugTII\\nee;f \\n  Let ii:Lgos n n \\n\\ne  r;QzQPrmo Lht somLKn I'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decode(model.generate(index = torch.zeros((1, 1), dtype=torch.long), max_new_token=100)[0].tolist())\n",
    "output = \"\".join(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b524af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1df84de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3,3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3263ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a / torch.sum(a, 1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fde6b242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4., 1.],\n",
       "        [9., 3., 4.],\n",
       "        [7., 1., 6.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randint(0,10,(3,3)).float()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a45c1e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000, 4.0000, 1.0000],\n",
       "        [6.0000, 3.5000, 2.5000],\n",
       "        [6.3333, 2.6667, 3.6667]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = a @ b\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03ad089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa990caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(4,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "571ffe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = torch.zeros((4,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18e25c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa263a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = F.softmax(wei, dim=1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0338bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "B,T,C = 4,8,32 # batch, time, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1de38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5413cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size)\n",
    "value = nn.Linear(C, head_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ccdf804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1ee990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = key(x)\n",
    "q = query(x)\n",
    "v = value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab0f1de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 16]), torch.Size([4, 8, 16]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape, k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d2168c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_key = q @ k.transpose(-1,-2) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0065a701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0508), tensor(1.0666), tensor(0.3416, grad_fn=<VarBackward0>))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
    "k.var(), q.var(), v.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98714551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62fa31d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3160, grad_fn=<StdBackward0>),\n",
       " tensor(0.0101, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_key.std(), query_key.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd600d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size(-1)\n",
    "d_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4a556af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8da20b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_key_scaled = query_key / torch.sqrt(torch.tensor(d_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ef19a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0025, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0790, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_key_scaled.mean(), query_key_scaled.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a4a7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(T,T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c31fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = tril.masked_fill(tril == 0, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2fdc3fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = wei.softmax(-1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4beae672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c87650a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "239bb1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 8])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.permute(0, 2, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c028d46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = wei @ v\n",
    "result.shape\n",
    "#This is the output of the attention mechanism for one head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58b2d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 10000\n",
    "eval_interval = 100\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0818678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5b1ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super(Head, self).__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size)\n",
    "        self.value = nn.Linear(n_embd, head_size)\n",
    "        self.query = nn.Linear(n_embd, head_size)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "        \n",
    "        \n",
    "        wei = q @ k.transpose(-1,-2) * head_size**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = wei.softmax(-1)\n",
    "        result = wei @ v\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f75d4a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = Head(head_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13d7992e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = get_batch(\"train\")\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "74a55fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(8,32,64)\n",
    "b = torch.randn(32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de152f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 64])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_b = (a + b)\n",
    "a_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58f1318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(32,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d83381fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(10, (32,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef39f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 64])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_emb = emb(a)\n",
    "a_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "77cab5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 32]), torch.Size([4, 8]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede55475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3ef4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, head_size, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.heads = ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3988b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e582fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "77596f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super(Block, self).__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.mha = MultiHeadAttention(head_size, n_head)\n",
    "        self.feed_forward = FeedForward(n_embd)\n",
    "        self.layer_norm1 = nn.LayerNorm(n_embd)\n",
    "        self.layer_norm2 = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.mha(self.layer_norm1(x))\n",
    "        x = x + self.feed_forward(self.layer_norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a430a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.token_embeddings = nn.Embedding(len(vocab_size), n_embd)\n",
    "        self.position_embeddings = nn.Embedding(block_size, n_embd)\n",
    "        \n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head) for _ in range(n_layer)])\n",
    "        self.layer_norm = nn.LayerNorm(len(vocab_size)-1)\n",
    "        self.feed_forward = nn.Linear(n_embd, len(vocab_size))\n",
    "    \n",
    "    def forward(self, idx, target=None):\n",
    "        B, T = idx.shape\n",
    "        tok_embd = self.token_embeddings(idx)\n",
    "        position_embeddings = self.position_embeddings(torch.arange(T))\n",
    "        \n",
    "        x = tok_embd + position_embeddings\n",
    "        x = self.blocks(x)\n",
    "        x = self.layer_norm(x)\n",
    "        logits = self.feed_forward(x)\n",
    "        \n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(batch_size * block_size, -1), target.view(-1))\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_token):\n",
    "        for i in range(max_new_token):\n",
    "            idx_cond = index[:, -block_size:]\n",
    "            output, loss = self(idx_cond)\n",
    "            output = output[:, -1, :].softmax(-1)\n",
    "            index_next = torch.multinomial(output, num_samples=1)\n",
    "            index = torch.cat((index, index_next), dim=1)\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c0600aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d3e5a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20fb8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "23e8ec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0| loss: 4.350693225860596\n",
      "iteration: 500| loss: 2.384089946746826\n",
      "iteration: 1000| loss: 2.271000623703003\n",
      "iteration: 1500| loss: 2.08839750289917\n",
      "iteration: 2000| loss: 1.972941279411316\n",
      "iteration: 2500| loss: 1.947158694267273\n",
      "iteration: 3000| loss: 1.9004379510879517\n",
      "iteration: 3500| loss: 1.864082932472229\n",
      "iteration: 4000| loss: 1.8159171342849731\n",
      "iteration: 4500| loss: 1.9053051471710205\n",
      "iteration: 5000| loss: 1.9047762155532837\n",
      "iteration: 5500| loss: 1.7336891889572144\n",
      "iteration: 6000| loss: 1.9031013250350952\n",
      "iteration: 6500| loss: 1.7895954847335815\n",
      "iteration: 7000| loss: 1.7797973155975342\n",
      "iteration: 7500| loss: 1.6494497060775757\n",
      "iteration: 8000| loss: 1.711073398590088\n",
      "iteration: 8500| loss: 1.7032816410064697\n",
      "iteration: 9000| loss: 1.660027027130127\n",
      "iteration: 9500| loss: 1.6481990814208984\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_iters):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 500 == 0:\n",
    "        print(f\"iteration: {i}| loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "93e94b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = decode(model.generate(index = torch.zeros((1, 1), dtype=torch.long), max_new_token=2000)[0].tolist())\n",
    "output = \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "22c4a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\".join(l for l in output.splitlines() if l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3a381b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You. Tirdan, comy be asheek leavelsTo thou hard in for asons'sbeindervy, shall our usper: 't my moralt,Beggelanst in emy appoply tenter that me within me,Which is a side majest: have! Relorsle, I up,No slep hanraten hele; have day.MENENE:You by with man, to foe? mastillont, hasts mon my Badied on my heare brother.To belight all stastaling my blet'sMy lord not day come tourve to dobe pat inpatianter; thou the, livent, but he's forge!No, in death sake him subjel'r: the by slaungeth, shall bethston her.Thy Seafferwerver:'Thon sloy shall speak hearst!VIR HORDWARD II:As say wharge, go turn, day, nothin reving of he battle imabe! bod less bouthde, so nemer wear map would look eyor king it contory.CORTIOLALUS:Fame is netsenteloust are ladtly,Sto blary letterable moss will all'tt, and thou an lookip sents, by lifest an of frommen!Gol, have to as geol, when no me.O me One my stilf ours.Tgrieves porens, gold mean a paleBetwell thy pet I sury was in gaes.DY:Second! A merve oge?ANNO:Make sail true so descangars more.KING HEWINRY VI:YrurGARD GAUDY VILIV:Botharen, is thrase thee, only woul sund and your lord,Here deathwe you hd enoy things be' in this vilsciel issing in one fack! if meath:He wriake noble row in eled: be me antumand love shert that's some attain's upon you. The spect min.QUEEN MIT:Yake doness porpreas, and to reathing my swear shall manwilling will ansubbid of be charry the she caper?CLAUDD OFICKENTIO:Hous hadf as see with ham poor aftly dubturen plary.BRUTUS:Eleters, an youTell is on nother in, as my eldome abot.DUKENBY:Hent wich and to harmistide, RurshFor thine she gol, and wail in ressWhich did tbe abag mess.JULINE:My breased this unhis all nather curecter,And fardit thy is man pers islay werringbreas he woon night,'Tis with stolse: the warwas to of It baliess in true!NORSAUTIGH:Go maid have brearity off daredingsels! and now deed man to man chole, and halstir,Hillous tir, with kell, impon thin \""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3c7be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
